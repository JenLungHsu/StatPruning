import torch
import torchvision.models as models
import torchvision.transforms as transforms
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from torchvision.models import *
import resnet_cifar10
import torchvision
import torchvision.transforms as transforms
import random

from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image

# === 1. æ¨¡å‹èˆ‡é è¨“ç·´æ¬Šé‡ ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model_ori = resnet_cifar10.__dict__['resnet110']()
ckpt = torch.load("/ssd5/Roy/pytorch_resnet_cifar10-master/pretrained_models/resnet110.th", weights_only=True, map_location=device)
state_dict = ckpt["state_dict"]
new_state_dict = {k.replace("module.", ""): v for k, v in state_dict.items()}
model_ori.load_state_dict(new_state_dict)
model_ori.cuda()

model_MW = resnet_cifar10.__dict__['resnet110_MW']()
ckpt = torch.load("/ssd5/Roy/pytorch_resnet_cifar10-master/save_resnet110/MW/best_model.th", weights_only=True, map_location=device)
state_dict = ckpt["state_dict"]
new_state_dict = {k.replace("module.", ""): v for k, v in state_dict.items()}
model_MW.load_state_dict(new_state_dict)

model_ori.eval().to(device)
model_MW.eval().to(device)

# === 2. Target layer (æœ€å¾Œä¸€å±¤ conv) ===
target_layers_ori = [model_ori.layer3[-1]]
target_layers_MW = [model_MW.layer3[-1]]

# === 3. åœ–ç‰‡è™•ç† ===

# è½‰æ›æ–¹å¼ï¼šå°‡åœ–ç‰‡è½‰ç‚º Tensor ä¸¦æ­£è¦åŒ–
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.4914, 0.4822, 0.4465],
        std=[0.2023, 0.1994, 0.2010]
    )
])

# è¼‰å…¥ CIFAR-10 è¨“ç·´è³‡æ–™é›†
dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)

# éš¨æ©ŸæŒ‘ä¸€å¼µåœ–ç‰‡
idx = random.randint(0, len(dataset) - 1)
image, label = dataset[idx]
input_tensor = image.unsqueeze(0).to(device)

# å°å‡ºåœ–åƒè³‡è¨Š
classes = dataset.classes
print(f"ğŸ–¼ï¸ éš¨æ©Ÿé¸å– CIFAR-10 åœ–ç‰‡ç´¢å¼•: {idx}")
print(f"ğŸ·ï¸ åœ–ç‰‡ Ground Truth é¡åˆ¥: {label} ({classes[label]})")

# å normalize + to numpy for overlay
inv_transform = transforms.Normalize(
    mean=[-0.4914/0.2023, -0.4822/0.1994, -0.4465/0.2010],
    std=[1/0.2023, 1/0.1994, 1/0.2010]
)
rgb_img = inv_transform(image).permute(1, 2, 0).numpy()
rgb_img = np.clip(rgb_img, 0, 1)

# === 5. Grad-CAM è¨­å®šèˆ‡æ¨è«– ===
cam_ori = GradCAM(model=model_ori, target_layers=target_layers_ori)
cam_MW = GradCAM(model=model_MW, target_layers=target_layers_MW)

# å–å¾—æ¨¡å‹é æ¸¬çš„é¡åˆ¥ï¼ˆä¹Ÿå¯ä»¥ç”¨ label æ›¿ä»£ï¼‰
with torch.no_grad():
    output = model_ori(input_tensor)
    predicted_class = output.argmax(dim=1).item()

targets = [ClassifierOutputTarget(predicted_class)]

# CAM
grayscale_cam_ori = cam_ori(input_tensor=input_tensor, targets=targets)[0]
grayscale_cam_MW = cam_MW(input_tensor=input_tensor, targets=targets)[0]

visualization_ori = show_cam_on_image(rgb_img, grayscale_cam_ori, use_rgb=True)
visualization_MW = show_cam_on_image(rgb_img, grayscale_cam_MW, use_rgb=True)

# === 6. é¡¯ç¤ºçµæœ ===
plt.imshow(rgb_img)
plt.axis('off')
plt.savefig("gradcam_cifar10_R110.png", bbox_inches='tight', pad_inches=0)
print("âœ”ï¸ Grad-CAM åœ–ç‰‡å·²å„²å­˜ç‚º gradcam_result.png")

plt.imshow(visualization_ori)
plt.axis('off')
plt.savefig("gradcam_cifar10_R110_ori.png", bbox_inches='tight', pad_inches=0)
print("âœ”ï¸ Grad-CAM åœ–ç‰‡å·²å„²å­˜ç‚º gradcam_result.png")

plt.imshow(visualization_MW)
plt.axis('off')
plt.savefig("gradcam_cifar10_R110_MW.png", bbox_inches='tight', pad_inches=0)
print("âœ”ï¸ Grad-CAM åœ–ç‰‡å·²å„²å­˜ç‚º gradcam_result.png")

